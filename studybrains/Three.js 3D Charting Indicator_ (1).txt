Visualizing Market Dynamics in State-Space: A three.js Implementation Blueprint for the kinētikós entropḗ Indicator




Part I: Deconstruction and Analysis of the State-Space Model


A robust and meaningful visualization must be a direct reflection of the model it represents. Before translating the kinētikós entropḗ indicator into a three.js environment, it is imperative to establish a definitive, shared understanding of its mechanics. This analysis synthesizes the extensive theoretical framework provided in the foundational documents with the concrete computational logic present in the JavaScript source code. This section deconstructs the four dimensions of the state vector, examines the data processing pipeline, and identifies critical considerations for a real-time, high-performance implementation.


Section 1: The Four Dimensions of Market State: A Synthesis


The kinētikós entropḗ indicator models the state of a financial asset at time t using a four-dimensional state vector, Ψ(t)=⟨P(t),M(t),E(t),Θ(t)⟩. Each component is derived from a distinct branch of physics and information theory, providing a holistic view of market dynamics that transcends traditional, single-factor indicators. The following analysis provides a canonical definition for each dimension.


Potential (P): The Energy of Market Tension


* Concept: Potential represents the stored energy within the market structure, arising from the price's deviation from a perceived equilibrium. It is a direct measure of market "tension".1 In classical mechanics, this is analogous to the potential energy of a spring that has been stretched or compressed from its resting position.
* Core Formula: The potential energy V of the system is defined by a function that combines a mean-reverting force and a persistent external drift 1:P(t)=V(p(t))=21​k(p(t)−peq​)2−Fp(t)
* Implementation: This formula is realized in the calculateStateVector function. The parameters are estimated in the preceding estimateMarketParameters function through a rolling regression analysis.
   * The mean-reversion constant, k, represents the "stiffness" of the market's tether to its equilibrium.
   * The equilibrium price, peq​, acts as the center of gravity for the price.
   * The persistent trend force, F, captures underlying bullish or bearish bias.
* Interpretation:
   * High Potential: A high value of P(t) signifies that the current price p(t) is significantly "stretched" away from its equilibrium peq​. This indicates a state of high tension and stores considerable potential energy that could be released as a sharp, corrective price movement.
   * Low Potential: A low value suggests the price is near its equilibrium, indicating a relaxed, low-tension market state.


Momentum (M): The Energy of Trend


* Concept: Momentum represents the kinetic energy of the current price trend, quantifying the power and conviction behind an ongoing move.1 It is the financial analogue of the energy of motion.
* Core Formula: The kinetic energy T is a function of the system's "mass" and "velocity" 1:M(t)=T(p(t))=21​m(p˙​(t))2
* Implementation: This is calculated within calculateStateVector.
   * The price velocity, p˙​(t), is the first derivative of the price series, robustly estimated using the savitzkyGolay filter, which fits a local polynomial to smooth the data and compute derivatives.1
   * The market "mass," m, represents the asset's inertia or resistance to a change in trend. In the estimateMarketParameters function, this is proxied by the ratio of average volume to average price over a lookback window.
* Interpretation:
   * High Momentum: A high value of M(t) indicates a strong, high-velocity trend (either bullish or bearish), signifying significant market conviction and energy.
   * Low Momentum: A low value indicates consolidation, a weak trend, or a pivotal turning point where price velocity is near zero.


Entropy (E): The Disorder of Price Velocity


* Concept: Entropy measures the system's disorder, randomness, and unpredictability.1 Rather than analyzing the price level, the "Lagrangian" perspective focuses on the entropy of the
price velocity, asking "How uncertain is the rate of change of the price?".1 This makes it a powerful tool for regime classification.
* Core Formula: The indicator uses the Shannon Entropy formula for a discrete variable X 1:E(t)=H(X)=−i=1∑n​p(xi​)log2​p(xi​)
* Implementation: The calculateRollingLagrangianEntropy function implements this concept.
   * Discretization: Since price_velocity is a continuous signal, it must be discretized into a finite set of states to use the Shannon formula. This is achieved by binning the data into numBins intervals. The probability p(xi​) of a given bin is its frequency within the entropyWindow.
   * Input Signal: The input to the calculation is the price_velocity series derived from the savitzkyGolay filter. A trending market (ordered velocity) will have low entropy, while a choppy, directionless market (disordered velocity) will have high entropy.1
   * Interpretation:
   * High Entropy: Signifies a chaotic, unpredictable market where price velocity is erratic. This is consistent with the Efficient Market Hypothesis (EMH), where price movements are random.1
   * Low Entropy: Signifies an ordered, patterned market where price velocity is consistent. This suggests the market is in a predictable trend, representing a deviation from pure efficiency.1


Temperature (Θ): The Fragility of the System


   * Concept: Economic Temperature measures the system's sensitivity or "excitability" to new capital flows or information. It is a forward-looking measure of market fragility.1
   * Core Formula: In thermodynamics, temperature is related to the change in entropy per unit of energy. The financial analogue defines temperature as the inverse of the change in entropy per unit of capital flow (proxied by volume) 1:Θ(t)∝​∂Volume∂E​​−1
   * Implementation: The calculateTemperature function implements this by estimating the derivative of volume with respect to entropy. As detailed in the research, a naive finite-difference approach is highly unstable for noisy financial data.1 Therefore, the implementation correctly uses a more robust method: a rolling linear regression of the change in volume (
ΔV) versus the change in entropy (ΔE) over a temperatureWindow. The slope of this regression, β, is the estimate for dVdE​. The temperature is then ∣β∣1​.
   * Interpretation:
      * High Temperature: A state where a small change in volume leads to a large change in entropy (i.e., the slope β is small). This describes a fragile, "hot," and highly sensitive market on the brink of a phase transition into chaos. It can serve as a leading indicator of a volatility spike. A slope of zero implies an infinite temperature.1
      * Low Temperature: A state where a large injection of capital (volume) produces only a small change in the system's disorder. This describes a stable, robust, and complacent market that can easily absorb flows.
The following table provides a consolidated reference for the four dimensions of the kinētikós entropḗ state vector.


Dimension
	Symbol
	Conceptual Meaning
	Core Formula (Theory)
	JavaScript Implementation
	Interpretation of High/Low Values
	Potential
	P
	Stored energy due to market structure and deviation from equilibrium.
	P(t)=21​k(p−peq​)2−Fp
	calculateStateVector
	High: Stretched, high tension, reversal risk.
Low: Relaxed, near equilibrium, low tension.
	Momentum
	M
	Kinetic energy of the current price trend.
	M(t)=21​m(p˙​)2
	calculateStateVector
	High: Strong, high-velocity trend.
Low: Consolidation, weak trend, low velocity.
	Entropy
	E
	System disorder, randomness, and unpredictability of price velocity.
	E(t)=−∑pi​log2​pi​
	calculateRollingLagrangianEntropy
	High: Unpredictable, random-like (efficient market).
Low: Ordered, patterned, predictable trend.
	Temperature
	Θ
	System sensitivity/excitability to new capital/information.
	$\Theta(t) \propto
	\frac{\partial E}{\partial V}
	^{-1}$
	

Section 2: The Calculation Pipeline and Performance Considerations


Understanding the sequence of calculations is crucial for both optimizing performance and ensuring the analytical integrity of the indicator. The current JavaScript implementation follows a clear causal chain, but this structure reveals both performance bottlenecks and a significant analytical caveat that must be addressed in the three.js version.


The Causal Chain of Calculation


The final 4D state vector is the result of a multi-stage pipeline where the output of one function becomes the input for the next:
      1. Data Fetching (fetchData): Raw time series data (timestamp, price, volume) is acquired.
      2. Smoothing and Derivative Estimation (savitzkyGolay): The raw price data is processed by a Savitzky-Golay filter. This is a critical pre-processing step that fits a local polynomial of order sg-poly over a sg-window. This yields a smoothed price series and, more importantly, robust estimates of the first derivative (price_velocity) and second derivative (price_acceleration).1
      3. Market Parameter Estimation (estimateMarketParameters): Using the smoothed data, a rolling linear regression is performed over a reg-window to estimate the core econophysics parameters: the mean-reversion constant (k), the trend force (F), and the market "mass" (m). This step involves computationally intensive matrix operations (math.lusolve).
      4. State Vector Calculation (calculateStateVector): The Potential (P) and Momentum (M) dimensions are computed using the outputs from the previous steps.
      5. Entropy Calculation (calculateRollingLagrangianEntropy): In parallel, the price_velocity series is fed into the entropy calculation, which uses a sliding window (entropyWindow) and a fixed number of bins (entropyBins) to compute the Shannon Entropy (E).
      6. Temperature Calculation (calculateTemperature): Finally, the entropy series and the raw volume data are used to calculate the Temperature (Θ) via another rolling regression over a temp-window.
This entire pipeline is executed on the CPU. The repeated loops and matrix inversions within the parameter estimation functions represent a significant performance bottleneck, especially for large datasets or real-time updates. A three.js implementation must consider offloading such heavy computations to the GPU.


The "Global Knowledge" Problem: A Critical Analytical Flaw


A meticulous review of the calculateRollingLagrangianEntropy and RegimeClassifier classes reveals a subtle but profound analytical issue: the introduction of look-ahead bias.
      * Source of the Bias:
      * In calculateRollingLagrangianEntropy, the binning range is determined by globalMin and globalMax, which are calculated by iterating over the entire input series before the rolling calculation begins.
      * Similarly, in RegimeClassifier, the .getPercentileRank() method compares the latest state variable to a distribution (this.sortedValues) that is pre-calculated from the entire historical dataset passed to its constructor.
      * Implication: This means that the value of Entropy or a regime score at a given time t is dependent on data from future time steps (t+k). For example, the globalMax of the velocity series might be set by a massive price spike that occurs a month after the point being calculated. This constitutes look-ahead bias, a critical flaw in any system intended for predictive analysis or realistic backtesting. The current implementation is valid only as a descriptive tool for a fixed historical dataset, not as a real-time indicator.
      * Consequence for three.js Implementation: This discovery forces a fundamental design decision for the new visualization.
      1. Option A (Historical Analysis Tool): Retain the current logic. The tool would be excellent for post-hoc analysis and generating the beautiful trajectories seen in the prototype, but it could not be used for live trading signals.
      2. Option B (Real-Time Indicator): Re-architect the normalization logic. Instead of using global minimums and maximums, the binning range for entropy and the percentile ranks for classification must be calculated based on a rolling window of past data only. This would make the indicator truly causal and suitable for real-time use, but it would also change its character. An entropy value of 2.5 would no longer have a fixed meaning across the entire timeline but would be relative to its own recent history.
For the purposes of this report, we will proceed with a design that can accommodate both scenarios. The core visualization techniques will be presented first, followed by advanced strategies for implementing a fully causal, real-time-compatible version.


Part II: Core Trajectory Visualization in three.js


The primary task is to migrate the 4D state-space plot from Plotly to three.js. This is not merely a change of library but an opportunity to create a far more expressive and data-rich representation. This part evaluates the optimal geometric primitives for the trajectory and provides a detailed blueprint for implementing a dynamic visualization that encodes all four dimensions of the kinētikós entropḗ state vector.


Section 3: Foundational Geometry: A Comparative Analysis


The choice of geometric primitive is the most fundamental decision in designing the visualization. While Plotly renders a simple line, three.js offers a spectrum of options, each with distinct capabilities and performance characteristics. The goal is to select a geometry that can serve as a rich canvas for encoding data.
      * THREE.Line: This is the most basic option, rendered using the WebGL primitive gl.LINE_STRIP.2 Its primary limitation is that the
linewidth property of its corresponding LineBasicMaterial is not reliably supported across all hardware and drivers, often rendering as a 1-pixel line regardless of the value set.3 This makes it unsuitable for a high-quality visualization where line thickness is a desirable visual variable.
      * Line2 ("Fat Lines"): This is the official three.js addon designed to solve the limitations of THREE.Line.4 It uses a custom geometry (
LineGeometry) and material (LineMaterial) to render lines with a consistent, controllable width, specified in either screen pixels or world units.5 It is performant and a significant step up from
THREE.Line, making it a strong contender for applications requiring simple, variable-width lines.7 However, it is still fundamentally a 2D construct billboarded in 3D space and lacks a true 3D surface for advanced shading.
      * MeshLine: This popular third-party library also renders lines using a triangle strip, effectively creating a 2D mesh that is always facing the camera.9 Its key advantage is its advanced
MeshLineMaterial, which supports features like dashing, textures (map, alphaMap), and variable width via a callback function, making it highly flexible for stylized line effects.9 While powerful, it remains an external dependency and, like
Line2, does not create a true 3D object with volumetric properties.
      * TubeGeometry: This standard three.js geometry creates a true 3D tube by extruding a circular cross-section along a 3D curve path.11 The result is a standard
THREE.Mesh with a fully defined 3D surface, complete with vertices, faces, normals, and UV coordinates. This is its paramount advantage. As a standard mesh, it can receive and cast shadows, be textured, and, most importantly, its vertex attributes (like position and color) can be manipulated in a custom shader. While it generates more vertices than the other methods, this richness of data provides unparalleled creative freedom.
Recommendation and Justification:
For the kinētikós entropḗ indicator, TubeGeometry is the unequivocally superior choice. The indicator is not a simple path but a container for four dimensions of rich data. The true 3D surface of a TubeGeometry provides the necessary canvas to encode this data. Its radius can be dynamically varied to represent one dimension (e.g., Momentum), while its surface color can be controlled on a per-vertex basis by another (e.g., Temperature). This capability to map multiple data dimensions onto the visual properties of a single geometric object is the key to creating an intuitive and insightful visualization that far surpasses a simple line plot.


Section 4: Implementing the Dynamic 4D Trajectory with TubeGeometry


This section provides a step-by-step implementation guide for creating a dynamic TubeGeometry that visually represents the full 4D state vector. The process involves creating a path from the state data, generating the tube, and applying a custom shader to encode the fourth dimension onto its surface color.


Path Creation from State-Space Coordinates


The foundation of the TubeGeometry is a path. The (Potential, Momentum, Entropy) coordinates of the state vector define the points in 3D space that this path will follow.
         1. Data Preparation: First, the 4D state vector data, currentValidData, must be processed. The P, M, and E values are extracted and converted into an array of THREE.Vector3 objects.
         2. Curve Generation: This array of points is used to create an instance of THREE.CatmullRomCurve3. This curve type is ideal as it generates a smooth, interpolated path that passes through all the given points, faithfully representing the trajectory's flow through the state-space.12


JavaScript




// Assume 'stateVectorData' is an array of objects { potential, momentum, entropy,... }
const points = stateVectorData.map(d => new THREE.Vector3(d.potential, d.momentum, d.entropy));

const path = new THREE.CatmullRomCurve3(points);



Dynamic Geometry and Updates


To handle dynamic data and ensure high performance, it is crucial to avoid recreating the TubeGeometry in every animation frame. The best practice is to create a geometry with pre-allocated buffers and update its attributes in place.14
         1. Initial Geometry: Create the TubeGeometry once with a sufficient number of segments to ensure smoothness.
JavaScript
const tubularSegments = 512; // Number of segments along the tube
const radius = 0.1;          // Base radius of the tube
const radialSegments = 8;    // Number of segments around the tube's circumference
const closed = false;

const geometry = new THREE.TubeGeometry(path, tubularSegments, radius, radialSegments, closed);

         2. Dynamic Updates: For subsequent updates (e.g., when the date range changes), you can update the geometry's position attribute directly. A new path is created from the new data, and its vertices are used to overwrite the existing position buffer.
JavaScript
// In an update function:
const newPoints = new_state_data.map(d => new THREE.Vector3(d.potential, d.momentum, d.entropy));
const newPath = new THREE.CatmullRomCurve3(newPoints);
const newPositions = new THREE.TubeGeometry(newPath, tubularSegments, radius, radialSegments, closed).attributes.position.array;

// Update the existing geometry's position attribute
trajectoryMesh.geometry.attributes.position.array.set(newPositions);
trajectoryMesh.geometry.attributes.position.needsUpdate = true; // Crucial!
trajectoryMesh.geometry.computeBoundingSphere(); // Important for camera and culling

Note that this approach assumes the number of vertices does not change. If the data length varies significantly, the recommended approach is to pre-allocate a very large buffer and use .setDrawRange() to control how much of it is rendered.14


Encoding the 4th Dimension (Temperature) via Custom Shaders


This is where the visualization transcends a simple plot. We will use a custom ShaderMaterial to color the tube's surface based on the Temperature (Θ) data, creating an intuitive heat map along the trajectory.15
            1. Create a Custom Attribute: For each vertex in the TubeGeometry, we need to know the corresponding Temperature. We can get an interpolated temperature value for each point along the generated tube path and create a Float32Array. This array is then added to the geometry as a custom attribute.
JavaScript
// After creating the TubeGeometry
const temperatures = new Float32Array(geometry.attributes.position.count);
const tempPath = new THREE.CatmullRomCurve3(stateVectorData.map(d => new THREE.Vector3(0, d.temperature, 0)));

for (let i = 0; i < temperatures.length; i++) {
   const u = i / (temperatures.length - 1); // Progress along the tube
   const tempPoint = tempPath.getPointAt(u);
   temperatures[i] = tempPoint.y; // Store the interpolated temperature
}

geometry.setAttribute('a_temperature', new THREE.BufferAttribute(temperatures, 1));

            2. Vertex Shader (vertexShader.glsl): The vertex shader's role is to receive the custom attribute and pass it to the fragment shader.
OpenGL Shading Language
// Custom attribute for temperature
attribute float a_temperature;

// Varying to pass temperature to the fragment shader
varying float v_temperature;

void main() {
   // Pass the temperature attribute to the varying
   v_temperature = a_temperature;

   // Standard position calculation
   gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
}

            3. Fragment Shader (fragmentShader.glsl): The fragment shader receives the interpolated temperature for each pixel on the tube's surface. It then uses this value to determine the final color. A mix() function is perfect for blending between two colors based on the temperature.
OpenGL Shading Language
// Uniforms for cool and hot colors, and normalization range
uniform vec3 u_coolColor;
uniform vec3 u_hotColor;
uniform float u_tempMin;
uniform float u_tempMax;

// Varying received from the vertex shader
varying float v_temperature;

void main() {
   // Normalize the temperature to a 0.0 - 1.0 range
   float normalizedTemp = (v_temperature - u_tempMin) / (u_tempMax - u_tempMin);
   normalizedTemp = clamp(normalizedTemp, 0.0, 1.0);

   // Mix between the cool and hot colors based on the normalized temperature
   vec3 finalColor = mix(u_coolColor, u_hotColor, normalizedTemp);

   gl_FragColor = vec4(finalColor, 1.0);
}

            4. JavaScript ShaderMaterial Setup: Finally, create the ShaderMaterial in JavaScript, defining the uniforms that the fragment shader needs.
JavaScript
const material = new THREE.ShaderMaterial({
   vertexShader: `...`,   // Content of vertexShader.glsl
   fragmentShader: `...`, // Content of fragmentShader.glsl
   uniforms: {
       u_coolColor: { value: new THREE.Color(0x0000ff) }, // Blue
       u_hotColor: { value: new THREE.Color(0xffff00) },  // Yellow
       u_tempMin: { value: Math.min(...temperatures) },
       u_tempMax: { value: Math.max(...temperatures) }
   }
});

const trajectoryMesh = new THREE.Mesh(geometry, material);
scene.add(trajectoryMesh);



Simultaneous Multi-Dimensional Encoding


The true power of this approach is its ability to encode multiple data dimensions onto the geometry simultaneously, creating a richer, more intuitive visual language. The TubeGeometry can be modified to represent not just Temperature but also Momentum and other variables.
               * Variable Radius for Momentum: A powerful trend (high Momentum) can be visualized as a thick, energetic tube, while a weak trend appears thin and frail. This requires modifying the TubeGeometry generation logic to accept a variable radius. While TubeGeometry does not support this natively, a custom geometry can be constructed by manually creating the vertices, where the radius at each segment along the path is scaled by the corresponding Momentum value.17
               * Emissive Intensity for Temperature: In addition to color, the Temperature can control the tube's glow. In the fragment shader, the gl_FragColor can be amplified for high temperatures. This will be the key to integrating with the post-processing bloom effect discussed in Part IV.
The following table summarizes these advanced data-encoding strategies.
Visual Property
	Data Dimension
	three.js Implementation Notes
	Pros
	Cons
	Path (X,Y,Z)
	Potential, Momentum, Entropy
	THREE.CatmullRomCurve3 from (P, M, E) coordinates.
	Core representation of the state-space trajectory.
	None; this is the fundamental mapping.
	Color
	Temperature (Θ)
	Custom ShaderMaterial with a mix() function in the fragment shader based on a custom a_temperature attribute.
	Intuitive "heat map" visualization of market fragility.
	Requires custom shaders.
	Radius
	Momentum (M)
	Custom geometry generation logic that varies the tube radius at each segment based on the Momentum value.
	Visually represents the "energy" or "power" of a trend. A thick tube is a strong trend.
	Adds complexity to geometry generation; not a standard TubeGeometry feature.17
	Emissive Glow
	Temperature (Θ)
	In the fragment shader, multiply the final color by a factor based on Temperature. color *= (1.0 + v_temperature * glow_factor);
	Creates a powerful visual highlight for "hot," high-risk market states. Essential for selective bloom.
	Requires post-processing (UnrealBloomPass) to be effective.
	By combining these techniques, the trajectory is transformed from a simple line into a dynamic, multi-faceted object whose very form and appearance convey the complex state of the market as described by the kinētikós entropḗ model.


Part III: Advanced Visualization: Animating the "Physics" with GPU-Accelerated Particles


To fully realize the "physics" inherent in the kinētikós entropḗ model, we must visualize the forces and flows it describes. A static trajectory, however well-colored, cannot convey concepts like flow, density, and agitation. This part proposes a paradigm shift: augmenting the core trajectory with a dynamic, high-performance particle system simulated entirely on the GPU. This "living" layer will transform the indicator from a chart into an interactive simulation.


Section 5: The "Living" Indicator: Conceptualizing a Particle System


The goal is to use a large number of particles to provide an intuitive, visual representation of the indicator's core concepts. The behavior of these particles—their speed, distribution, and agitation—will be directly driven by the 4D state vector data along the trajectory.
               * Flow and Momentum (M): Particles will be initialized along the TubeGeometry path and will flow along it over time. The fundamental innovation is that the velocity of each particle will be directly proportional to the Momentum value at its current position on the curve. In regions of high Momentum, particles will flow rapidly, visualizing a strong, energetic trend. In regions of low Momentum, they will slow to a crawl, depicting consolidation or a loss of energy.
               * Density, Disorder, and Entropy (E): The Entropy dimension measures the disorder of price velocity. This can be visualized by controlling the particles' spatial distribution. In low-entropy regions (ordered trend), particles will be tightly constrained to the central curve of the tube. In high-entropy regions (chaotic market), a noise function in the particle simulation will push them outwards, causing them to occupy the full volume of the tube in a more diffuse, cloud-like formation. This visually translates high entropy into a high-volume, disordered particle cloud.
               * Agitation and Temperature (Θ): The Temperature dimension measures market fragility and excitability. This can be visualized by adding a random, high-frequency "jitter" to each particle's movement. The magnitude of this jitter will be scaled by the Temperature value. In low-temperature (cool, stable) regions, particles will flow smoothly. In high-temperature (hot, fragile) regions, they will appear agitated and turbulent, as if vibrating with excess energy, providing a clear visual warning of market instability.


Section 6: High-Performance Simulation with GPUComputationRenderer


Simulating the physics of hundreds of thousands of particles on the CPU in JavaScript is computationally infeasible and would result in catastrophic performance. The only viable solution is to offload the entire simulation to the GPU using a technique known as GPGPU (General-Purpose computing on Graphics Processing Units).


Core Concept: GPGPU and Data Textures


The GPGPU paradigm leverages the massively parallel architecture of the GPU, designed for processing millions of pixels simultaneously, to perform general-purpose calculations.18 The key is to store data not in arrays but in textures. Each pixel (or texel) in a texture can store a vector of numbers (typically RGBA), which can represent any data we choose, such as a particle's 3D position (in RGB) and its remaining lifetime (in A).19 By writing custom shaders that read from input textures and write to an output texture, we can perform complex calculations on every particle in parallel.


GPUComputationRenderer: The three.js GPGPU Helper


three.js provides a powerful helper class, GPUComputationRenderer, that abstracts away much of the complexity of GPGPU.20 It manages the creation of floating-point render targets (textures that can store high-precision data) and handles the "ping-pong" process: using the result of the previous frame (read buffer) as the input for the current frame's calculation (write buffer), then swapping them for the next frame.22


Implementation Blueprint


               1. Initialization:
               * Instantiate GPUComputationRenderer with the desired texture dimensions (e.g., 512x512 for 262,144 particles).
               * Create initial data textures for particle positions and velocities. The initial positions can be sampled randomly from the surface of the TubeGeometry using MeshSurfaceSampler.18
               * Add these textures as "variables" to the GPUComputationRenderer, associating each with a custom fragment shader that defines its update logic.
               2. Compute Shaders (GLSL): Two fragment shaders are required to run the simulation. These shaders are the core of the GPGPU engine.
               * velocityFragmentShader.glsl: This shader calculates the new velocity for each particle. At each frame, for each particle, it will:
a. Read the particle's current position from the position texture.
b. Find the closest point on the main trajectory curve.
c. Read the Momentum, Entropy, and Temperature data for that point on the curve (this data must be passed to the shader, likely via another data texture).
d. Calculate a composite force: a force pulling the particle back towards the curve, a tangential force pushing it along the curve (scaled by Momentum), and a random noise vector (scaled by Entropy and Temperature).
e. Compute the new velocity based on this force and write it to the output velocity texture.
               * positionFragmentShader.glsl: This shader is simpler. For each particle, it will:
a. Read the particle's current position from the position texture.
b. Read the particle's newly computed velocity from the velocity texture.
c. Calculate the new position: new_pos = old_pos + new_vel * delta_time.
d. Write the result to the output position texture.
                  3. Variable Dependencies: Set up the data flow within the GPUComputationRenderer using .setVariableDependencies(). The position calculation depends on the velocity calculation, and the velocity calculation depends on the previous frame's position and velocity.21
                  4. Rendering:
                  * In the main animation loop, first call gpuCompute.compute() to run one step of the simulation.
                  * The particle system itself is a THREE.Points object.
                  * Its material is a ShaderMaterial. The crucial step is to pass the GPUComputationRenderer's current position texture as a uniform to this material.
                  * The vertex shader for the Points material is remarkably simple. Each vertex doesn't need a position attribute; instead, it looks up its own position from the texture passed in as a uniform. This links the rendered points directly to the simulated data on the GPU.


A Fully-Integrated GPU Pipeline


The approach described above involves calculating the main 4D trajectory on the CPU and passing that data to the GPU particle simulation as uniforms or data textures. For the ultimate in performance and scalability, the entire indicator calculation pipeline can be ported to the GPU.
This advanced architecture would involve creating a series of compute shaders to perform the Savitzky-Golay filtering, the rolling regressions for parameter estimation, and the entropy calculations directly on the GPU. The raw price and volume data would be loaded into textures, and a chain of GPGPU passes would process this data, with the final output being a set of data textures representing the time series of the P,M,E, and Θ dimensions.
These final data textures would then be fed directly into the shaders for rendering the TubeGeometry and simulating the particle system. This creates a seamless, end-to-end GPU pipeline where raw market data enters and a fully rendered, physically-simulated visualization emerges, with minimal CPU intervention or costly CPU-GPU data transfers. While more complex to implement, this architecture is the state-of-the-art solution for real-time analysis of massive, high-frequency datasets and represents the full realization of the "physics" inherent in the kinētikós entropḗ model.


Part IV: Achieving a Modern Aesthetic and Full Interactivity


A powerful analytical tool must also be a pleasure to use. The final stage of development focuses on polishing the visual presentation to achieve the desired "super modern" aesthetic and implementing the robust, intuitive interactivity required for professional-grade data exploration. This involves leveraging post-processing for visual effects and Raycaster for precise user interaction.


Section 7: Post-Processing for Visual Impact with Selective Bloom


A key requirement is to make the visualization look "super modern," which often implies effects like glows and atmospheric lighting. Post-processing allows for the application of such effects to the entire rendered scene. The UnrealBloomPass is particularly effective for creating a beautiful, soft glow. The challenge is to apply this effect selectively, making only the most significant parts of the trajectory glow.


The EffectComposer Pipeline


Post-processing in three.js is managed by the EffectComposer. Instead of rendering directly to the screen, the renderer renders to an intermediate buffer. A series of "passes" then read from this buffer, apply an effect, and write to another buffer in a "ping-pong" fashion. The final pass renders to the screen.23 The basic setup involves:
                  1. Creating an EffectComposer instance.
                  2. Adding a RenderPass, which renders the main scene.
                  3. Adding one or more effect passes, such as UnrealBloomPass.
                  4. Calling composer.render() instead of renderer.render() in the animation loop.


Data-Driven Selective Bloom: The Modern Approach


There are two primary methods for achieving selective bloom. The older, more complex method involves using THREE.Layers to render the scene multiple times, manually darkening non-blooming objects in one pass.26 This is inefficient.
The modern, recommended, and far more elegant approach is to use a single UnrealBloomPass and control which objects glow based on their material's color intensity.28 The
UnrealBloomPass has a threshold property. It will only apply the bloom effect to pixels whose final rendered color has a luminance value above this threshold. Typically, colors are in the `` range. By setting the threshold to 1.0, only "High Dynamic Range" (HDR) colors with component values greater than 1 will glow.
This mechanism integrates perfectly with the custom shader developed in Part II. We can directly link the glow effect to the Temperature data:
                  1. Modify the Trajectory's Fragment Shader: The fragment shader for the TubeGeometry will be modified. In addition to calculating the finalColor based on temperature, it will also calculate an emissiveIntensity. This intensity will be 0.0 for low temperatures and will scale up to values greater than 1.0 for high temperatures. The final output color will be multiplied by this intensity.
OpenGL Shading Language
// In the fragment shader for the tube material
varying float v_temperature;
uniform float u_tempMin;
uniform float u_tempMax;
uniform float u_glowIntensity; // A new uniform to control max glow

void main() {
   float normalizedTemp = clamp((v_temperature - u_tempMin) / (u_tempMax - u_tempMin), 0.0, 1.0);
   vec3 finalColor = mix(u_coolColor, u_hotColor, normalizedTemp);

   // Make the color emissive based on temperature
   // Only high temperatures will push the color value > 1.0
   float emissiveFactor = pow(normalizedTemp, 4.0) * u_glowIntensity;
   gl_FragColor = vec4(finalColor * (1.0 + emissiveFactor), 1.0);
}

                  2. Configure UnrealBloomPass: Add the UnrealBloomPass to the EffectComposer with its threshold set to 1.0.
JavaScript
const bloomPass = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
bloomPass.threshold = 1.0; // Only bloom colors > 1.0
bloomPass.strength = 1.2;  // Adjust glow intensity
bloomPass.radius = 0.5;    // Adjust glow radius
composer.addPass(bloomPass);

This approach is exceptionally powerful. It achieves perfect, data-driven selective bloom with zero additional render passes or complex scene manipulation. The "hot," high-risk segments of the financial trajectory will now literally glow with an intensity proportional to their Temperature value, providing an immediate and intuitive visual cue of market fragility.


Section 8: Building an Interactive Analysis Tool with Raycaster


A static visualization is of limited use. To transform the dashboard into a true analytical tool, the user must be able to interact with it, probe the data, and build an intuition for how state-space patterns correspond to price action. THREE.Raycaster is the standard and robust three.js class for implementing this mouse-picking functionality.30


Raycaster Fundamentals for Mouse Picking


The process involves casting a virtual ray from the camera's position through the mouse's 2D screen position and into the 3D scene, then detecting which objects this ray intersects.
                     1. Event Listener: An event listener for pointermove or click is added to the renderer's DOM element.
                     2. Normalize Mouse Coordinates: Inside the listener, the mouse's clientX and clientY are converted into Normalized Device Coordinates (NDC), which range from -1 to +1 on both axes.31
                     3. Set and Cast Ray: An instance of THREE.Raycaster is updated with the camera and normalized mouse coordinates using raycaster.setFromCamera(mouse, camera).
                     4. Check for Intersections: The .intersectObject() or .intersectObjects() method is called, passing the object(s) to be tested (in this case, the trajectoryMesh). This returns an array of intersection objects, sorted by distance from the camera.32


JavaScript




const raycaster = new THREE.Raycaster();
const pointer = new THREE.Vector2();

function onPointerMove(event) {
   // Calculate pointer position in normalized device coordinates
   pointer.x = (event.clientX / window.innerWidth) * 2 - 1;
   pointer.y = - (event.clientY / window.innerHeight) * 2 + 1;

   // Update the picking ray
   raycaster.setFromCamera(pointer, camera);

   // Calculate objects intersecting the picking ray
   const intersects = raycaster.intersectObject(trajectoryMesh);

   if (intersects.length > 0) {
       // An intersection was found, process it
       processIntersection(intersects);
   }
}
window.addEventListener('pointermove', onPointerMove);



Linking 3D Intersection to the Original Data


The intersects array contains rich information for each intersection, including the point of intersection in 3D space (point), the distance from the camera (distance), and, most importantly, the index of the triangular face that was hit (faceIndex).33 This
faceIndex is the key to linking the 3D visualization back to the original source data.
The vertices of a TubeGeometry are generated in a predictable order. The faceIndex gives us the specific triangle that was hit. A triangle is defined by three vertices. From the geometry.index attribute, we can get the indices of these three vertices (a, b, c). These vertex indices correspond directly to the points along the generated tube. By determining how far along the tube these vertices are, we can find the corresponding index in our original stateVectorData array. This allows us to retrieve the precise Potential, Momentum, Entropy, and Temperature values for the point on the trajectory the user is hovering over.


Creating the Tooltip and Highlighting


Once the underlying data for the hovered point is retrieved, it can be displayed to the user.
                     * Tooltip: A simple HTML <div> can be used as a tooltip. Its content is populated with the retrieved data (P, M, E, Θ, and the corresponding date). Its position is updated using CSS transforms to follow the mouse cursor or to be placed at the 2D screen projection of the 3D intersection point.
                     * Highlighting: To provide clear visual feedback, the intersected part of the tube can be highlighted. This can be achieved by directly manipulating the color attribute of the geometry's buffers. By accessing the vertex indices (a, b, c) from the intersected face, we can change the color values for those specific vertices in the geometry.attributes.color buffer and set .needsUpdate = true. This will cause only the hovered triangle to change color, creating a precise highlighting effect.
This combination of Raycaster, data mapping, and dynamic UI elements provides the full suite of interactive features required for a professional-grade analytical dashboard, allowing users to seamlessly explore the deep, multi-dimensional data captured by the kinētikós entropḗ indicator.


Part V: Synthesis and Final Implementation


This final part consolidates the preceding analysis into a coherent structure, presenting the complete code for a reusable three.js component and offering recommendations for performance tuning and future enhancements. The goal is to provide a comprehensive and actionable blueprint that directly replaces and dramatically improves upon the original Plotly visualization.


Section 9: The Complete three.js Component


The following represents a well-structured, commented implementation that integrates the core concepts: TubeGeometry for the trajectory, a custom ShaderMaterial for data-driven coloring and emissive glow, GPUComputationRenderer for the physics-based particle system, EffectComposer with UnrealBloomPass for post-processing, and Raycaster for full interactivity. This code is designed to be encapsulated within a single class or module for easy integration into the existing full-stack application.


JavaScript




// --- KinētikósEntropḗ_3D.js ---
import * as THREE from 'three';
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js';
import { EffectComposer } from 'three/examples/jsm/postprocessing/EffectComposer.js';
import { RenderPass } from 'three/examples/jsm/postprocessing/RenderPass.js';
import { UnrealBloomPass } from 'three/examples/jsm/postprocessing/UnrealBloomPass.js';
import { GPUComputationRenderer } from 'three/examples/jsm/misc/GPUComputationRenderer.js';

// Import GLSL shaders as text (using a bundler like Vite with vite-plugin-glsl)
import tubeVertexShader from './shaders/tube/vertex.glsl';
import tubeFragmentShader from './shaders/tube/fragment.glsl';
import particlePositionShader from './shaders/particles/position.glsl';
import particleVelocityShader from './shaders/particles/velocity.glsl';
import particleRenderVertexShader from './shaders/particles/render_vertex.glsl';
import particleRenderFragmentShader from './shaders/particles/render_fragment.glsl';


export class KineticosEntrope3D {
   constructor(container) {
       this.container = container;
       this.init();
   }

   init() {
       // --- Basic Scene Setup ---
       this.scene = new THREE.Scene();
       this.camera = new THREE.PerspectiveCamera(75, this.container.clientWidth / this.container.clientHeight, 0.1, 1000);
       this.camera.position.set(0, 0, 10);

       this.renderer = new THREE.WebGLRenderer({ antialias: true });
       this.renderer.setSize(this.container.clientWidth, this.container.clientHeight);
       this.renderer.setPixelRatio(window.devicePixelRatio);
       this.container.appendChild(this.renderer.domElement);

       this.controls = new OrbitControls(this.camera, this.renderer.domElement);

       // --- Post-Processing Setup ---
       this.composer = new EffectComposer(this.renderer);
       this.composer.addPass(new RenderPass(this.scene, this.camera));

       const bloomPass = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
       bloomPass.threshold = 1.0; // Only bloom HDR colors
       bloomPass.strength = 1.5;
       bloomPass.radius = 0.8;
       this.composer.addPass(bloomPass);

       // --- Interactivity Setup ---
       this.raycaster = new THREE.Raycaster();
       this.pointer = new THREE.Vector2();
       this.container.addEventListener('pointermove', this.onPointerMove.bind(this));
       
       // --- Tooltip ---
       this.tooltip = document.createElement('div');
       this.tooltip.style.position = 'absolute';
       this.tooltip.style.display = 'none';
       //... add glass-panel styling from original CSS
       this.container.appendChild(this.tooltip);

       this.animate();
   }
   
   // Method to be called when new data is available
   updateData(stateVectorData) {
       this.stateVectorData = stateVectorData;
       
       // Remove old objects if they exist
       if (this.trajectoryMesh) this.scene.remove(this.trajectoryMesh);
       if (this.particleSystem) this.scene.remove(this.particleSystem);

       this.createTrajectory();
       this.createParticleSystem();
   }

   createTrajectory() {
       const points = this.stateVectorData.map(d => new THREE.Vector3(d.potential, d.momentum, d.entropy));
       const path = new THREE.CatmullRomCurve3(points);

       const geometry = new THREE.TubeGeometry(path, 512, 0.1, 16, false);
       
       // --- Add custom attributes for shader ---
       const temperatures = new Float32Array(geometry.attributes.position.count);
       const momentums = new Float32Array(geometry.attributes.position.count);
       
       // Interpolate data along the tube's vertices
       for (let i = 0; i < geometry.attributes.position.count; i++) {
           const u = i / (geometry.attributes.position.count - 1);
           const dataIndex = Math.floor(u * (this.stateVectorData.length - 1));
           temperatures[i] = this.stateVectorData[dataIndex].temperature;
           momentums[i] = this.stateVectorData[dataIndex].momentum;
       }
       
       geometry.setAttribute('a_temperature', new THREE.BufferAttribute(temperatures, 1));
       geometry.setAttribute('a_momentum', new THREE.BufferAttribute(momentums, 1));

       const tempStats = { min: Math.min(...temperatures), max: Math.max(...temperatures) };
       const momStats = { min: Math.min(...momentums), max: Math.max(...momentums) };

       const material = new THREE.ShaderMaterial({
           vertexShader: tubeVertexShader,
           fragmentShader: tubeFragmentShader,
           uniforms: {
               u_coolColor: { value: new THREE.Color(0x3b82f6) }, // blue-500
               u_hotColor: { value: new THREE.Color(0xfde047) },   // yellow-300
               u_tempMin: { value: tempStats.min },
               u_tempMax: { value: tempStats.max },
               u_glowIntensity: { value: 3.0 }
           },
           side: THREE.DoubleSide
       });

       this.trajectoryMesh = new THREE.Mesh(geometry, material);
       this.scene.add(this.trajectoryMesh);
   }

   createParticleSystem() {
       const PARTICLE_WIDTH = 256; // 256*256 = 65536 particles
       this.gpuCompute = new GPUComputationRenderer(PARTICLE_WIDTH, PARTICLE_WIDTH, this.renderer);

       // --- Create initial data textures ---
       const posTexture = this.gpuCompute.createTexture();
       const velTexture = this.gpuCompute.createTexture();
       
       // Sample initial positions from the trajectory mesh
       const sampler = new THREE.MeshSurfaceSampler(this.trajectoryMesh).build();
       const posData = posTexture.image.data;
       for (let i = 0; i < posData.length; i += 4) {
           const newPos = new THREE.Vector3();
           sampler.sample(newPos);
           posData[i] = newPos.x;
           posData[i + 1] = newPos.y;
           posData[i + 2] = newPos.z;
           posData[i + 3] = Math.random(); // Lifetime
       }

       // --- Add compute shader variables ---
       this.velVariable = this.gpuCompute.addVariable('textureVelocity', particleVelocityShader, velTexture);
       this.posVariable = this.gpuCompute.addVariable('texturePosition', particlePositionShader, posTexture);
       
       this.gpuCompute.setVariableDependencies(this.velVariable, [this.posVariable, this.velVariable]);
       this.gpuCompute.setVariableDependencies(this.posVariable, [this.posVariable, this.velVariable]);
       
       // Pass trajectory data to the velocity shader
       // (Simplified here: passing the full path as a uniform array is limited by size.
       // A better approach is to bake the path data into another texture.)
       this.velVariable.material.uniforms['u_time'] = { value: 0.0 };
       //... add uniforms for path data, temperature, momentum etc.

       const error = this.gpuCompute.init();
       if (error!== null) console.error(error);

       // --- Create render geometry/material ---
       const particleGeometry = new THREE.BufferGeometry();
       const uvs = new Float32Array(PARTICLE_WIDTH * PARTICLE_WIDTH * 2);
       for (let i = 0; i < PARTICLE_WIDTH; i++) {
           for (let j = 0; j < PARTICLE_WIDTH; j++) {
               const index = i * PARTICLE_WIDTH + j;
               uvs[index * 2] = j / (PARTICLE_WIDTH - 1);
               uvs[index * 2 + 1] = i / (PARTICLE_WIDTH - 1);
           }
       }
       particleGeometry.setAttribute('uv', new THREE.BufferAttribute(uvs, 2));

       const particleMaterial = new THREE.ShaderMaterial({
           uniforms: {
               texturePosition: { value: null },
               u_pointSize: { value: 2.0 }
           },
           vertexShader: particleRenderVertexShader,
           fragmentShader: particleRenderFragmentShader,
           blending: THREE.AdditiveBlending,
           transparent: true,
           depthWrite: false
       });

       this.particleSystem = new THREE.Points(particleGeometry, particleMaterial);
       this.scene.add(this.particleSystem);
   }
   
   onPointerMove(event) {
       this.pointer.x = (event.clientX / this.container.clientWidth) * 2 - 1;
       this.pointer.y = - (event.clientY / this.container.clientHeight) * 2 + 1;
       
       this.raycaster.setFromCamera(this.pointer, this.camera);
       const intersects = this.raycaster.intersectObject(this.trajectoryMesh);

       if (intersects.length > 0) {
           const intersection = intersects;
           const faceIndex = intersection.faceIndex;
           // From faceIndex, get vertex indices, then map back to original data array index
           // This logic can be complex, requires mapping tube segments back to path segments.
           // Simplified for demonstration:
           const dataIndex = Math.floor(intersection.uv.x * (this.stateVectorData.length - 1));
           const dataPoint = this.stateVectorData[dataIndex];
           
           this.tooltip.style.display = 'block';
           this.tooltip.style.left = `${event.clientX + 15}px`;
           this.tooltip.style.top = `${event.clientY}px`;
           this.tooltip.innerHTML = `
               Date: ${new Date(dataPoint.timestamp).toLocaleDateString()}<br>
               Potential: ${dataPoint.potential.toExponential(2)}<br>
               Momentum: ${dataPoint.momentum.toExponential(2)}<br>
               Entropy: ${dataPoint.entropy.toFixed(3)}<br>
               Temperature: ${dataPoint.temperature.toExponential(2)}
           `;
       } else {
           this.tooltip.style.display = 'none';
       }
   }

   animate() {
       requestAnimationFrame(this.animate.bind(this));
       this.controls.update();

       if (this.gpuCompute) {
           this.gpuCompute.compute();
           this.velVariable.material.uniforms['u_time'].value = performance.now() / 1000;
           this.particleSystem.material.uniforms['texturePosition'].value = this.gpuCompute.getCurrentRenderTarget(this.posVariable).texture;
       }

       this.composer.render();
   }
}



Section 10: Performance Tuning and Future Directions


The proposed implementation provides a powerful and visually rich platform for analyzing the kinētikós entropḗ indicator. However, for applications involving extremely long time series or true real-time data streaming, further optimizations and architectural considerations are necessary.


Performance Tuning


                     * Level of Detail (LOD): For very long trajectories that span years of data, rendering a high-resolution TubeGeometry with thousands of segments can become a performance bottleneck. A THREE.LOD object can be used to manage this. Multiple versions of the TubeGeometry can be created at different resolutions (e.g., high, medium, low tubularSegments). The LOD object will automatically switch to the appropriate geometry based on its distance from the camera, ensuring smooth performance when zoomed out while retaining detail when zoomed in.
                     * Data Streaming and setDrawRange: For a live-updating indicator, it is inefficient to destroy and recreate the geometry with each new data point. The optimal approach is to initialize a BufferGeometry with a very large, pre-allocated buffer (e.g., for a million vertices). As new data streams in, it is written into the buffer. The .setDrawRange(start, count) method is then used to tell the renderer to only draw the most recent segment of the buffer.14 This allows for a "comet trail" effect, visualizing the most recent market history without any object creation/destruction overhead in the animation loop.
                     * Particle System Optimization: The number of particles is a direct trade-off with performance. While GPGPU is highly efficient, simulating millions of particles will still tax the GPU. The number of particles should be a user-configurable setting to allow for tuning on different hardware.


Future Directions and Enhancements


The kinētikós entropḗ framework is a foundational methodology with significant potential for extension.
                     * Advanced Entropy Measures: The current implementation uses binned Shannon Entropy. The research documents suggest several advanced, time-series-specific entropy measures that could be explored.1
                     * Permutation Entropy (PE): This method is based on the ordinal patterns (rankings) of values in the time series, not their absolute magnitudes. This makes it inherently robust to outliers and removes the need for the critical numBins parameter, simplifying the model.
                     * Approximate/Sample Entropy (ApEn/SampEn): These measures quantify the regularity and predictability of a time series and are designed to work well with shorter, noisier datasets.
                     * Implementing these alternative entropy calculations could yield a more robust or nuanced Entropy dimension.
                     * Multi-Asset System Modeling: The true power of the Lagrangian framework lies in its generalizability. While this report focuses on a single asset, the model can be extended to a system of multiple, interacting assets. This would involve adding coupling terms to the potential energy function in the Lagrangian, representing the forces that correlated assets exert on each other. The resulting visualization would be a set of interacting trajectories in the state-space, providing a powerful tool for analyzing systemic risk, contagion, and relative value within an entire market ecosystem.
By pursuing these advanced techniques, the kinētikós entropḗ indicator and its visualization can evolve from a single-asset analysis tool into a comprehensive platform for understanding the complex, interconnected dynamics of modern financial markets.
Works cited
                     1. 2rsfobs.txt
                     2. Line - Three.js, accessed June 27, 2025, https://threejs.org/docs/api/en/objects/Line.html
                     3. Implementing Three.Line2 in Typescript/R3F : r/threejs - Reddit, accessed June 27, 2025, https://www.reddit.com/r/threejs/comments/15kjaoe/implementing_threeline2_in_typescriptr3f/
                     4. Line2 – three.js docs, accessed June 27, 2025, https://threejs.org/docs/examples/en/lines/Line2.html
                     5. LineGeometry – three.js docs, accessed June 27, 2025, https://threejs.org/docs/examples/en/lines/LineGeometry.html
                     6. LineSegmentsGeometry – three.js docs, accessed June 27, 2025, https://threejs.org/docs/examples/en/lines/LineSegmentsGeometry.html
                     7. three.js webgl - lines - fat, accessed June 27, 2025, https://gkjohnson.github.io/threejs-sandbox/fat-line-opacity/webgl_lines_fat.html
                     8. Fat Lines in threejs by making use of additional files - Dustin Pfister, accessed June 27, 2025, https://dustinpfister.github.io/2018/11/07/threejs-line-fat-width/
                     9. spite/THREE.MeshLine: Mesh replacement for THREE.Line - GitHub, accessed June 27, 2025, https://github.com/spite/THREE.MeshLine
                     10. Animating Lines and Curves in Three.js with MeshLine - Wael Yasmina, accessed June 27, 2025, https://waelyasmina.net/articles/animating-lines-and-curves-in-three-js-with-meshline/
                     11. TubeGeometry – three.js docs, accessed June 27, 2025, https://threejs.org/docs/api/en/geometries/TubeGeometry.html
                     12. How can I make good tube with three.js? for example railings - Questions, accessed June 27, 2025, https://discourse.threejs.org/t/how-can-i-make-good-tube-with-three-js-for-example-railings/79506
                     13. How to create a tube from my array of coordinates (x, y, z)? - three.js forum, accessed June 27, 2025, https://discourse.threejs.org/t/how-to-create-a-tube-from-my-array-of-coordinates-x-y-z/50331
                     14. Dynamic BufferGeometry disappears when re-setting the position buffer attribute - Questions, accessed June 27, 2025, https://discourse.threejs.org/t/dynamic-buffergeometry-disappears-when-re-setting-the-position-buffer-attribute/49274
                     15. ShaderMaterial – three.js docs, accessed June 27, 2025, https://threejs.org/docs/api/en/materials/ShaderMaterial.html
                     16. Creating a custom shader in Three.js - DEV Community, accessed June 27, 2025, https://dev.to/maniflames/creating-a-custom-shader-in-threejs-3bhi
                     17. three.js tube with variable radius - Stack Overflow, accessed June 27, 2025, https://stackoverflow.com/questions/20955852/three-js-tube-with-variable-radius
                     18. Crafting a Dreamy Particle Effect with Three.js and GPGPU - Codrops, accessed June 27, 2025, https://tympanus.net/codrops/2024/12/19/crafting-a-dreamy-particle-effect-with-three-js-and-gpgpu/
                     19. GPGPU Flow Field Particles Shaders - Three.js Journey, accessed June 27, 2025, https://threejs-journey.com/lessons/gpgpu-flow-field-particles-shaders
                     20. How to use three.js for GPGPU? - Questions, accessed June 27, 2025, https://discourse.threejs.org/t/how-to-use-three-js-for-gpgpu/2388
                     21. epranka/gpucomputationrender-three: GPUComputationRender module for Three.js with ES6 compatibility - GitHub, accessed June 27, 2025, https://github.com/epranka/gpucomputationrender-three
                     22. [SOLVED] Swapping render targets with GPUComputationRenderer - three.js forum, accessed June 27, 2025, https://discourse.threejs.org/t/solved-swapping-render-targets-with-gpucomputationrenderer/6299
                     23. EffectComposer – three.js docs, accessed June 27, 2025, https://threejs.org/docs/examples/en/postprocessing/EffectComposer.html
                     24. Post-processing - Three.js Journey, accessed June 27, 2025, https://threejs-journey.com/lessons/post-processing
                     25. Post-Processing with Three.js - The What and How - Wael Yasmina, accessed June 27, 2025, https://waelyasmina.net/articles/post-processing-with-three-js-the-what-and-how/
                     26. Make the Sun Shine - Sangil Lee, accessed June 27, 2025, https://sangillee.com/2025-01-28-selective-bloom-effect/
                     27. Unreal Bloom Selective - Three.js Post Processing - Wael Yasmina, accessed June 27, 2025, https://waelyasmina.net/articles/unreal-bloom-selective-threejs-post-processing/
                     28. Postprocessing selective bloom - Questions - three.js forum, accessed June 27, 2025, https://discourse.threejs.org/t/postprocessing-selective-bloom/61645
                     29. Is there a selective bloom pass other than the threejs example? - Questions, accessed June 27, 2025, https://discourse.threejs.org/t/is-there-a-selective-bloom-pass-other-than-the-threejs-example/60155
                     30. Raycaster – three.js docs, accessed June 27, 2025, https://threejs.org/docs/api/en/core/Raycaster.html
                     31. Raycaster and Mouse Events - Three.js Journey, accessed June 27, 2025, https://threejs-journey.com/lessons/raycaster-and-mouse-events
                     32. three.js raycaster is selecting all objects behind and in front of the object I want to select - Stack Overflow, accessed June 27, 2025, https://stackoverflow.com/questions/59866523/three-js-raycaster-is-selecting-all-objects-behind-and-in-front-of-the-object-i
                     33. Raycaster - Three.js Tutorials, accessed June 27, 2025, https://sbcode.net/threejs/raycaster/